#!/usr/bin/env python

import os
import urllib
import urllib2
import shutil
import xml.etree.ElementTree as ET
import process_image

# API constants
API_ENTRY = 'https://api.flickr.com/services/rest/'
API_KEY = 'xxx'	# replace with your own key to work
INTERESTINGNESS = 'flickr.interestingness.getList'
BASE_URL = API_ENTRY + '?method=' + INTERESTINGNESS + '&api_key=' + API_KEY

# path constants
IMG_PATH = 'xxx' # replace with your own path to work

# retrieve the bucket the photo should be in
def get_bucket(rgb):
    INTERVAL = 15
    r = int(rgb[0] / INTERVAL * INTERVAL)
    g = int(rgb[1] / INTERVAL * INTERVAL)
    b = int(rgb[2] / INTERVAL * INTERVAL)

    dst_folder = IMG_PATH + "r" + str(r) + "g" + str(g) + "b" + str(b) + "/"
    return dst_folder

# save image to cache and update database
def save_img(img_url):
    urllib.urlretrieve(img_url, IMG_PATH + 'tmp.jpg')
    rgb = process_image.get_avg_rgb(IMG_PATH + 'tmp.jpg')
    dst_path = get_bucket(rgb)
    file_num = 0

    # check if folder exists, and if not, create it
    if not os.path.exists(dst_path):
        os.makedirs(dst_path)

    # count number of pictures currently in the folder
    for root, dirs, files in os.walk(dst_path):
        for file in files:
            if file.endswith(".jpg"):
                file_num += 1

    src = IMG_PATH + "tmp.jpg"
    dst = dst_path + str(file_num) + ".jpg"
    shutil.move(src, dst)


# construct photo_url from photo attributes in XML response
def get_photo_urls(photos):
    urls = []
    for photo in photos:
	attribs = photo.attrib
	farm_id = attribs['farm']
	server_id = attribs['server']
	id = attribs['id']
	secret = attribs['secret']
	url = 'https://farm' + farm_id + '.staticflickr.com/' + server_id + '/' + id + '_' + secret + '_q.jpg'
	urls.append(url)
    return urls

# fetch interesting images of the day from Flickr
def fetch_images():
    try:
	response = urllib2.urlopen(BASE_URL)
    except urllib2.URLError as e:
	print 'Reason: ', e.reason
    else:
	tree = ET.parse(response)
	photos = tree.findall('photos/photo')
	urls = get_photo_urls(photos)
	return urls


urls = fetch_images()
for url in urls:
    save_img(url)
